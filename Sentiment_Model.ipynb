{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make compatible with Python 2 and Python 3\n",
    "from __future__ import print_function, division, absolute_import \n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head -n4 data/labeledTrainData.tsv \n",
    "# use bash command to see data set structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data to a Pandas data frame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd       \n",
    "train = pd.read_csv(\"data/labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "# train.shape should be (25000,3)\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"data/testData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         25000 non-null  object\n",
      " 1   sentiment  25000 non-null  int64 \n",
      " 2   review     25000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "\n",
      "Number of Data Samples for every label output. 1=postive, 2=negative:\n",
      "1    12500\n",
      "0    12500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. \n",
    "print(train.shape)\n",
    "print()\n",
    "print('Number of Data Samples for every label output. 1=postive, 2=negative:')\n",
    "print(train.sentiment.value_counts())\n",
    "\n",
    "train.sentiment.hist(); #class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of the reviews are:\n",
      "1329.71056\n"
     ]
    }
   ],
   "source": [
    "# 2. Apply length function to the review column\n",
    "lengths = train['review'].apply(len)\n",
    "\n",
    "print('Average character length of the reviews are:')\n",
    "print (np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\muska_000\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import bs4 as bs\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "print(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def review_cleaner(review):\n",
    "    '''\n",
    "    Clean and preprocess a review.\n",
    "    \n",
    "    1. Remove HTML tags\n",
    "    2. Use regex to remove all special characters (only keep letters)\n",
    "    3. Make strings to lower case and tokenize / word split reviews\n",
    "    4. Remove English stopwords\n",
    "    5. Rejoin to one string\n",
    "    '''\n",
    "    \n",
    "    #1. Remove HTML tags\n",
    "    review = bs.BeautifulSoup(review).text\n",
    "    \n",
    "    #2. Use regex to find emoticons\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
    "    \n",
    "    #3. Remove punctuation\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
    "    \n",
    "    #4. Tokenize into words (all lower case)\n",
    "    review = review.lower().split()\n",
    "    \n",
    "    #5. Remove stopwords\n",
    "    eng_stopwords = set(stopwords.words(\"english\"))\n",
    "    review = [w for w in review if not w in eng_stopwords]\n",
    "    \n",
    "    #6. Join the review to one sentence\n",
    "    review = ' '.join(review+emoticons)\n",
    "    # add emoticons to the end\n",
    "\n",
    "    return(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 500 reviews\n",
      "Done with 1000 reviews\n",
      "Done with 1500 reviews\n",
      "Done with 2000 reviews\n",
      "Done with 2500 reviews\n",
      "Done with 3000 reviews\n",
      "Done with 3500 reviews\n",
      "Done with 4000 reviews\n",
      "Done with 4500 reviews\n",
      "Done with 5000 reviews\n",
      "Done with 5500 reviews\n",
      "Done with 6000 reviews\n",
      "Done with 6500 reviews\n",
      "Done with 7000 reviews\n",
      "Done with 7500 reviews\n",
      "Done with 8000 reviews\n",
      "Done with 8500 reviews\n",
      "Done with 9000 reviews\n",
      "Done with 9500 reviews\n",
      "Done with 10000 reviews\n",
      "Done with 10500 reviews\n",
      "Done with 11000 reviews\n",
      "Done with 11500 reviews\n",
      "Done with 12000 reviews\n",
      "Done with 12500 reviews\n",
      "Done with 13000 reviews\n",
      "Done with 13500 reviews\n",
      "Done with 14000 reviews\n",
      "Done with 14500 reviews\n",
      "Done with 15000 reviews\n",
      "Done with 15500 reviews\n",
      "Done with 16000 reviews\n",
      "Done with 16500 reviews\n",
      "Done with 17000 reviews\n",
      "Done with 17500 reviews\n",
      "Done with 18000 reviews\n",
      "Done with 18500 reviews\n",
      "Done with 19000 reviews\n",
      "Done with 19500 reviews\n",
      "Done with 20000 reviews\n",
      "Done with 20500 reviews\n",
      "Done with 21000 reviews\n",
      "Done with 21500 reviews\n",
      "Done with 22000 reviews\n",
      "Done with 22500 reviews\n",
      "Done with 23000 reviews\n",
      "Done with 23500 reviews\n",
      "Done with 24000 reviews\n",
      "Done with 24500 reviews\n",
      "Done with 25000 reviews\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_reviews = len(train['review'])\n",
    "\n",
    "review_clean_original = []\n",
    "\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1)%500 == 0 ):\n",
    "        # print progress\n",
    "        print(\"Done with %d reviews\" %(i+1)) \n",
    "    review_clean_original.append(review_cleaner(train['review'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics # for confusion matrix, accuracy score etc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "    review_clean_original, train['sentiment'], random_state=0, test_size=.2)\n",
    "\n",
    "\n",
    "# CountVectorizer can actucally handle a lot of the preprocessing for us\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=5000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Transform the text data to feature\n",
    "# Only fit training data (to mimic real world)\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned', 'abc', 'abilities', 'ability', 'able', 'abraham', 'absence', 'absent', 'absolute', 'absolutely']\n"
     ]
    }
   ],
   "source": [
    "# Check that it worked, \n",
    "# now we have fitted a model that can transform features\n",
    "# to sparse matrix representation\n",
    "\n",
    "print(vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = vectorizer.transform(X_train) #transform to a feature matrix\n",
    "test_bag = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_bag) # sparse matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Initialize a Random Forest classifier with 50 trees\n",
    "# hyperparameter n_estimators always set in instantiation\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the target variable\n",
    "\n",
    "forest = forest.fit(train_bag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "train_predictions = forest.predict(train_bag)\n",
    "valid_predictions = forest.predict(test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train,train_predictions) # 100% training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,valid_predictions) # 83% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2164,  384],\n",
       "       [ 420, 2032]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "# Is the number of False Positives and True negatives approx 50/50?\n",
    "metrics.confusion_matrix(y_test,valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 420)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test,valid_predictions).ravel()\n",
    "fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "filename = 'RFModel.pkl'\n",
    "pickle.dump(forest,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'FVectorizer.pkl'\n",
    "pickle.dump(vectorizer,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model from disk\n",
    "loaded_model = pickle.load(open('RFModel.pkl','rb'))\n",
    "test_bag = vectorizer.transform([review_cleaner('this was a bad movie')]).toarray()\n",
    "pred = loaded_model.predict(test_bag)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
